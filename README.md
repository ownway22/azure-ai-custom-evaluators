# ğŸ§ª Azure AI Custom Evaluators ç¯„ä¾‹
æœ¬ç¯„ä¾‹èªªæ˜å¦‚ä½•åœ¨æœ¬æ©ŸåŸ·è¡Œ2å€‹è‡ªè¨‚çš„å®¢è£½æŒ‡æ¨™ï¼ˆClarityã€Helpfulnessï¼‰ï¼Œä¸¦é‡å°æŒ‡å®šçš„ LLM Response è³‡æ–™é›†ï¼ˆ`dataset.jsonl`ï¼‰é€²è¡Œè©•ä¼°ï¼Œå…¶è©•ä¼°çµæœæœƒä¸Šå‚³è‡³Azure AI Foundry Projectä¸­ä½œå‘ˆç¾ã€‚è«‹ä¾ä¸‹åˆ—æ­¥é©Ÿå®Œæˆç’°å¢ƒè¨­å®šèˆ‡ç¯„ä¾‹ç¨‹å¼ç¢¼åŸ·è¡Œã€‚

## å°ˆæ¡ˆçµæ§‹
```text
azure-ai-custom-evaluators/
â”œâ”€ clarity.py                     # Clarity å®¢è£½æŒ‡æ¨™å¯¦ä½œï¼ˆå¥é•·ã€å†—é•·æ¯”ä¾‹ç­‰ï¼‰
â”œâ”€ clarity_evaluation.py          # Clarity å®¢è£½æŒ‡æ¨™ç¯„ä¾‹
â”œâ”€ helpfulness.py                 # Helpfulness å®¢è£½æŒ‡æ¨™ï¼ˆé€é promptflow + LLMï¼‰
â”œâ”€ helpfulness_evaluation.py      # Helpfulness å®¢è£½æŒ‡æ¨™ç¯„ä¾‹
â”œâ”€ helpfulness.prompty            # Helpfulness çš„ promptflow å®šç¾©
â”œâ”€ local_evaluation.py            # å° dataset.jsonl åŸ·è¡Œæ‰¹æ¬¡è©•ä¼°ä¸¦è¼¸å‡ºçµæœ
â”œâ”€ dataset.jsonl                  # æ¸¬è©¦è³‡æ–™ï¼ˆJSONLï¼‰
â”œâ”€ requirements.txt               # pip ä¾è³´
â”œâ”€ pyproject.toml                 # å°ˆæ¡ˆå®šç¾©ï¼ˆå« Python ç‰ˆæœ¬è¦æ±‚ï¼‰
â”œâ”€ sample_env_rename_it           # ç’°å¢ƒè®Šæ•¸æ¨£æ¿ï¼Œè«‹å¦å­˜ç‚º .env
â””â”€ myevalresults.json             # åŸ·è¡Œå¾Œç”¢ç”Ÿçš„æœ¬æ©Ÿè©•ä¼°çµæœï¼ˆæª”æ¡ˆä¸å­˜åœ¨æ™‚æœƒæ–°å¢ï¼‰
```

## è³‡æ–™é›†æ ¼å¼ï¼ˆdataset.jsonlï¼‰
- æª”æ¡ˆé¡å‹ç‚º JSON Linesï¼›æ¯è¡Œè‡³å°‘åŒ…å«ï¼š
  - `id`: ç¯„ä¾‹è­˜åˆ¥ç¢¼
  - `response`: è¦è©•ä¼°çš„ç­”æ¡ˆæ–‡å­—
- ç¯„ä¾‹å…§å®¹ï¼š
  ```jsonl
  {"id": "1", "response": "The process has three steps. First, submit your form online..."}
  {"id": "2", "response": "In order to achieve the objective, it is necessary that the applicant..."}
  ```

## æ­¥é©Ÿä¸€ï¼šæº–å‚™ç’°å¢ƒ
- Python ç’°å¢ƒ
  - Python ç‰ˆæœ¬è‡³å°‘ 3.8
    - æ­¤å°ˆæ¡ˆçš„ `pyproject.toml` æ˜¯æŒ‡å®š `requires-python == 3.11.12`ï¼Œåƒ…ä¾›åƒè€ƒ
    - æª¢æŸ¥ Python ç‰ˆæœ¬ï¼Œä»¥ Windows ç’°å¢ƒç‚ºä¾‹ï¼Œé€é PowerShell åŸ·è¡Œ
        ```powershell
        python --version
        ```

- Azure AI Foundry è³‡æº
    - å‰å¾€ Azure AI Foundry Portalï¼š[https://ai.azure.com/](https://ai.azure.com/) 
    - æ–°å¢æˆ–æ‰¾åˆ°æ—¢æœ‰çš„ AI å°ˆæ¡ˆï¼Œä¸¦é€²å…¥å°ˆæ¡ˆé é¢
    - å‰å¾€ã€ŒEndpoints and keysã€æˆ–ã€Œç«¯é»èˆ‡é‡‘é‘°ã€æŸ¥çœ‹ï¼Œå¦‚ä¸‹åœ–æ‰€ç¤º
        ![complete](azure-ai-get-language-endpoint-and-key.png)

    - å–å¾— Azure AI Services çš„ Endpoint èˆ‡ Keyï¼Œå°‡æ–¼æ­¥é©Ÿäº”ä¸­ä½¿ç”¨
        - `AZURE_AI_FOUNDRY_PROJECT_ENDPOINT`
        - `AZURE_OPENAI_ENDPOINT`
        - `AZURE_AI_KEY`
        - `MODEL_EVALUATION_DEPLOYMENT_NAME`
        - `MODEL_GENAIAPP_DEPLOYMENT_NAME`

## æ­¥é©ŸäºŒï¼šå–å¾—æˆ–åˆ‡æ›åˆ°æ­¤è³‡æ–™å¤¾
- ä½¿ç”¨ Gitï¼š
    ```powershell
    git clone https://github.com/ownway22/azure-ai-custom-evaluators.git
    cd <ä½ çš„-repoè³‡æ–™å¤¾>/azure-pii-sample-code
    ```

- æˆ–ç›´æ¥å°‡æœ¬è³‡æ–™å¤¾ä¸‹è¼‰åˆ°æœ¬æ©Ÿã€‚

## æ­¥é©Ÿä¸‰ï¼šå•Ÿå‹•è™›æ“¬ç’°å¢ƒ
- åœ¨ `<ä½ çš„-repoè³‡æ–™å¤¾>/azure-pii-sample-code` ç›®éŒ„ä¸‹åŸ·è¡Œï¼š
    ```powershell
    python -m venv .venv                # å»ºç«‹è™›æ“¬ç’°å¢ƒ
    .venv\Scripts\Activate              # å•Ÿå‹•è™›æ“¬ç’°å¢ƒ
    ```

## æ­¥é©Ÿå››ï¼šå®‰è£ç›¸ä¾å¥—ä»¶
- æœ¬å°ˆæ¡ˆæä¾› `requirements.txt` å’Œ `pyproject.toml` åšå®‰è£
- ä»¥ `requirements.txt` ç‚ºä¾‹
    ```powershell
    python -m pip install --upgrade pip # å‡ç´š pip
    pip install -r requirements.txt     # å®‰è£ç›¸ä¾å¥—ä»¶
    ```

## æ­¥é©Ÿäº”ï¼šæº–å‚™ç’°å¢ƒè®Šæ•¸
- å°‡ `.env_example` å¦å­˜ç‚º `.env`
- è²¼ä¸Šæ­¥é©Ÿä¸€çš„5å€‹ç’°å¢ƒè®Šæ•¸

## æ­¥é©Ÿå…­ï¼šåŸ·è¡Œç¯„ä¾‹èˆ‡è©•ä¼°
ä½ å¯ä»¥é¸æ“‡å–®ç¨åŸ·è¡Œå®¢è£½æŒ‡æ¨™çš„ç¯„ä¾‹ï¼Œæˆ–ç›´æ¥åŸ·è¡Œæ‰¹æ¬¡è©•ä¼°ã€‚

1) å®¢è£½æŒ‡æ¨™ç¯„ä¾‹1 - ã€Œæ¸…æ™°åº¦ï¼ˆClarityï¼‰ã€
    ```powershell
    python .\clarity_evaluation.py

    # æˆ–ä½¿ç”¨ uvï¼ˆè‹¥å·²å®‰è£ï¼‰
    uv run .\clarity_evaluation.py
    ```

2) å®¢è£½æŒ‡æ¨™ç¯„ä¾‹2 - ã€Œæœ‰ç”¨æ€§ï¼ˆHelpfulnessï¼‰ã€
    ```powershell
    python .\helpfulness_evaluation.py

    # æˆ–ä½¿ç”¨ uvï¼ˆè‹¥å·²å®‰è£ï¼‰
    uv run .\helpfulness_evaluation.py
    ```

3) ä»¥ä¸Šè¿°å…©å€‹æŒ‡æ¨™é‡å° LLM Response è³‡æ–™é›†ï¼ˆ`dataset.jsonl`ï¼‰é€²è¡Œè©•ä¼°ï¼Œä¸¦å°‡è©•ä¼°çµæœå­˜æˆ `myevalresults.json`
    ```powershell
    # ä½¿ç”¨ python
    python .\local_evaluation.py

    # æˆ–ä½¿ç”¨ uvï¼ˆè‹¥å·²å®‰è£ï¼‰
    uv run .\local_evaluation.py
    ```

## è¼¸å‡ºçµæœ
- æ‰¹æ¬¡è©•ä¼°æœƒåœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„è¼¸å‡º `myevalresults.json`ã€‚
- è‹¥ `.env` å…§æä¾›ä¸”æœ‰æ•ˆçš„ `AZURE_AI_FOUNDRY_PROJECT_ENDPOINT`ï¼Œçµæœä¹Ÿæœƒå˜—è©¦ä¸Šå‚³è‡³ Azure AI Studio å°ˆæ¡ˆã€‚
  - è‹¥ä¸Šå‚³å¤±æ•—ï¼ˆä¾‹å¦‚ 404/Resource not foundï¼‰ï¼ŒæŒ‡ä»¤æœƒé¡¯ç¤ºè­¦å‘Šä¸¦è‡ªå‹•æ”¹ç‚ºåƒ…æœ¬æ©Ÿè¼¸å‡ºï¼Œä¸æœƒä¸­æ–·æµç¨‹ã€‚

## ç–‘é›£æ’è§£ï¼ˆTroubleshootingï¼‰
- é™æ¸¬ä¸Šå‚³ 404ï¼Resource not foundï¼š
  - æª¢æŸ¥ `AZURE_AI_FOUNDRY_PROJECT_ENDPOINT` æ˜¯å¦ç‚ºæœ‰æ•ˆçš„ HTTP(S) URLï¼Œä¸”ç¢ºå¯¦æŒ‡å‘ä½ è¦ä¸Šå‚³çš„ Azure AI Studio å°ˆæ¡ˆã€‚
  - è‹¥ä»å¤±æ•—ï¼ŒæŒ‡ä»¤æœƒè‡ªå‹•é€€å›æœ¬æ©Ÿè¼¸å‡º `myevalresults.json`ã€‚

- Helpfulness å®¢è£½æŒ‡æ¨™å¤±æ•—æˆ–å›å‚³ç©ºåˆ†æ•¸ï¼š
  - ç¢ºèª `.env` å·²å¡«å…¥ `AZURE_OPENAI_ENDPOINT`ã€`MODEL_EVALUATION_DEPLOYMENT_NAME`ã€`AZURE_AI_KEY`ã€‚
  - ç¢ºèªä½ çš„æ¨¡å‹éƒ¨ç½²å¯ç”¨ï¼Œä¸”å¸³æˆ¶å…·å‚™å‘¼å«æ¬Šé™ã€‚
  - æª¢æŸ¥ `helpfulness.prompty` æ˜¯å¦å­˜åœ¨ä¸”å¯è¢« `promptflow` è¼‰å…¥ã€‚

- å¥—ä»¶å®‰è£å•é¡Œï¼š
  - å„ªå…ˆç¢ºèªå·²å•Ÿå‹•æœ¬è³‡æ–™å¤¾ä¸‹çš„ `.venv` å¾Œå†å®‰è£ã€‚
  - è‹¥ä½¿ç”¨ `pip` ä»é‡åˆ°ç›¸ä¾è¡çªï¼Œå¯å˜—è©¦ `uv pip install -r requirements.txt`ã€‚

## Reference
1. [Custom evaluators - Azure AI Foundry | Microsoft Learn](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/evaluation-evaluators/custom-evaluators)

2. [Building Your Own Custom Evaluator for GenAI Apps, Agents, and Models Using Azure AI Foundry SDK - DEV Community](https://dev.to/icebeam7/building-your-own-custom-evaluator-for-genai-apps-agents-and-models-using-azure-ai-foundry-sdk-1okg)